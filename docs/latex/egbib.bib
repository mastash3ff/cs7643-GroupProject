
@misc{Authors14,
 author = {Authors},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture  submission ID 324. Supplied as additional material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {Authors},
 title = {Frobnication tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = {Journal of Foo},
volume = 12, 
number = 1, 
pages = {234--778}, 
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13, 
number = 1, 
pages = {234--778}, 
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14, 
number = 1, 
pages = {234--778}, 
year = 2004
}

@article{mmdetection, 
  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark}, 
  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and 
             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and 
             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and 
             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and 
             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong 
             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua}, 
  journal= {arXiv preprint arXiv:1906.07155}, 
  year={2019} 
} 

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{khan2021transformers,
  title={Transformers in vision: A survey},
  author={Khan, Salman and Naseer, Muzammal and Hayat, Munawar and Zamir, Syed Waqas and Khan, Fahad Shahbaz and Shah, Mubarak},
  journal={ACM Computing Surveys (CSUR)},
  year={2021},
  publisher={ACM New York, NY}
}

@article{liu2021survey,
  title={A Survey of Visual Transformers},
  author={Liu, Yang and Zhang, Yao and Wang, Yixin and Hou, Feng and Yuan, Jin and Tian, Jiang and Zhang, Yang and Shi, Zhongchao and Fan, Jianping and He, Zhiqiang},
  journal={arXiv preprint arXiv:2111.06091},
  year={2021}
}

@article{lin2021survey,
  title={A survey of transformers},
  author={Lin, Tianyang and Wang, Yuxin and Liu, Xiangyang and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2106.04554},
  year={2021}
}

@article{han2020survey,
  title={A survey on vision transformer},
  author={Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others},
  journal={arXiv preprint arXiv:2012.12556},
  year={2020}
}

@article{hashemi2015survey,
  title={A survey of visual attention models},
  author={Hashemi, Seyyed Mohammad Reza},
  journal={Ci{\^e}ncia e Natura},
  volume={37},
  pages={297--306},
  year={2015}
}

@article{hafiz2021attention,
  title={Attention mechanisms and deep learning for machine vision: A survey of the state of the art},
  author={Hafiz, Abdul Mueed and Parah, Shabir Ahmad and Bhat, Rouf Ul Alam},
  journal={arXiv preprint arXiv:2106.07550},
  year={2021}
}

@article{zaidi2022survey,
  title={A survey of modern deep learning based object detection models},
  author={Zaidi, Syed Sahil Abbas and Ansari, Mohammad Samar and Aslam, Asra and Kanwal, Nadia and Asghar, Mamoona and Lee, Brian},
  journal={Digital Signal Processing},
  pages={103514},
  year={2022},
  publisher={Elsevier}
}

@article{jiao2019survey,
  title={A survey of deep learning-based object detection},
  author={Jiao, Licheng and Zhang, Fan and Liu, Fang and Yang, Shuyuan and Li, Lingling and Feng, Zhixi and Qu, Rong},
  journal={IEEE access},
  volume={7},
  pages={128837--128868},
  year={2019},
  publisher={IEEE}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@article{guo2021attention,
  title={Attention Mechanisms in Computer Vision: A Survey},
  author={Guo, Meng-Hao and Xu, Tian-Xing and Liu, Jiang-Jiang and Liu, Zheng-Ning and Jiang, Peng-Tao and Mu, Tai-Jiang and Zhang, Song-Hai and Martin, Ralph R and Cheng, Ming-Ming and Hu, Shi-Min},
  journal={arXiv preprint arXiv:2111.07624},
  year={2021}
}

@article{meinhardt2021trackformer,
  title={Trackformer: Multi-object tracking with transformers},
  author={Meinhardt, Tim and Kirillov, Alexander and Leal-Taixe, Laura and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2101.02702},
  year={2021}
}

@article{xu2022transformers,
  title={Transformers in computational visual media: A survey},
  author={Xu, Yifan and Wei, Huapeng and Lin, Minxuan and Deng, Yingying and Sheng, Kekai and Zhang, Mengdan and Tang, Fan and Dong, Weiming and Huang, Feiyue and Xu, Changsheng},
  journal={Computational Visual Media},
  volume={8},
  number={1},
  pages={33--62},
  year={2022},
  publisher={Springer}
}

@article{yang2022transformers,
  title={Transformers Meet Visual Learning Understanding: A Comprehensive Review},
  author={Yang, Yuting and Jiao, Licheng and Liu, Xu and Liu, Fang and Yang, Shuyuan and Feng, Zhixi and Tang, Xu},
  journal={arXiv preprint arXiv:2203.12944},
  year={2022}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{correia2021attention,
  title={Attention, please! a survey of neural attention models in deep learning},
  author={Correia, Alana de Santana and Colombini, Esther Luna},
  journal={arXiv preprint arXiv:2103.16775},
  year={2021}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@article{zhao2019object,
  title={Object detection with deep learning: A review},
  author={Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-tao and Wu, Xindong},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={11},
  pages={3212--3232},
  year={2019},
  publisher={IEEE}
}

@article{raghu2021vision,
  title={Do vision transformers see like convolutional neural networks?},
  author={Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{dong2021cswin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  journal={arXiv preprint arXiv:2107.00652},
  year={2021}
}

@inproceedings{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={568--578},
  year={2021}
}

@inproceedings{ranftl2021vision,
  title={Vision transformers for dense prediction},
  author={Ranftl, Ren{\'e} and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12179--12188},
  year={2021}
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@inproceedings{chen2021crossvit,
  title={Crossvit: Cross-attention multi-scale vision transformer for image classification},
  author={Chen, Chun-Fu Richard and Fan, Quanfu and Panda, Rameswar},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={357--366},
  year={2021}
}

@inproceedings{wu2021cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22--31},
  year={2021}
}

@article{zhou2021deepvit,
  title={Deepvit: Towards deeper vision transformer},
  author={Zhou, Daquan and Kang, Bingyi and Jin, Xiaojie and Yang, Linjie and Lian, Xiaochen and Jiang, Zihang and Hou, Qibin and Feng, Jiashi},
  journal={arXiv preprint arXiv:2103.11886},
  year={2021}
}

@inproceedings{zhang2021multi,
  title={Multi-scale vision longformer: A new vision transformer for high-resolution image encoding},
  author={Zhang, Pengchuan and Dai, Xiyang and Yang, Jianwei and Xiao, Bin and Yuan, Lu and Zhang, Lei and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2998--3008},
  year={2021}
}

@article{han2021transformer,
  title={Transformer in transformer},
  author={Han, Kai and Xiao, An and Wu, Enhua and Guo, Jianyuan and Xu, Chunjing and Wang, Yunhe},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{chen2021visformer,
  title={Visformer: The vision-friendly transformer},
  author={Chen, Zhengsu and Xie, Lingxi and Niu, Jianwei and Liu, Xuefeng and Wei, Longhui and Tian, Qi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={589--598},
  year={2021}
}

@article{chen2021psvit,
  title={Psvit: Better vision transformer via token pooling and attention sharing},
  author={Chen, Boyu and Li, Peixia and Li, Baopu and Li, Chuming and Bai, Lei and Lin, Chen and Sun, Ming and Yan, Junjie and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2108.03428},
  year={2021}
}

@InProceedings{liu2021efficient,
    author    = {Liu, Yahui and Sangineto, Enver and Bi, Wei and Sebe, Nicu and Lepri, Bruno and De Nadai, Marco},
    title     = {Efficient Training of Visual Transformers with Small Datasets},
    booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},
    year      = {2021}
}


@article{chen2021vision,
  title={When vision transformers outperform ResNets without pre-training or strong data augmentations},
  author={Chen, Xiangning and Hsieh, Cho-Jui and Gong, Boqing},
  journal={arXiv preprint arXiv:2106.01548},
  year={2021}
}

@misc{https://doi.org/10.48550/arxiv.2010.01412,
  doi = {10.48550/ARXIV.2010.01412},
  
  url = {https://arxiv.org/abs/2010.01412},
  
  author = {Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Sharpness-Aware Minimization for Efficiently Improving Generalization},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2203.09795,
  doi = {10.48550/ARXIV.2203.09795},
  
  url = {https://arxiv.org/abs/2203.09795},
  
  author = {Touvron, Hugo and Cord, Matthieu and El-Nouby, Alaaeldin and Verbeek, Jakob and Jégou, Hervé},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Three things everyone should know about Vision Transformers},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{https://doi.org/10.48550/arxiv.2104.14294,
  doi = {10.48550/ARXIV.2104.14294},
  
  url = {https://arxiv.org/abs/2104.14294},
  
  author = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jégou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Emerging Properties in Self-Supervised Vision Transformers},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{https://doi.org/10.48550/arxiv.2104.14294,
  doi = {10.48550/ARXIV.2104.14294},
  
  url = {https://arxiv.org/abs/2104.14294},
  
  author = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jégou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Emerging Properties in Self-Supervised Vision Transformers},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@InProceedings{pmlr-v139-touvron21a,
  title =     {Training data-efficient image transformers &amp; distillation through attention},
  author =    {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jegou, Herve},
  booktitle = {International Conference on Machine Learning},
  pages =     {10347--10357},
  year =      {2021},
  volume =    {139},
  month =     {July}
}

@INPROCEEDINGS{Geiger2012CVPR,
  author = {Andreas Geiger and Philip Lenz and Raquel Urtasun},
  title = {Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2012}
}

@article{nuscenes2019,
  title={nuScenes: A multimodal dataset for autonomous driving},
  author={Holger Caesar and Varun Bankiti and Alex H. Lang and Sourabh Vora and 
          Venice Erin Liong and Qiang Xu and Anush Krishnan and Yu Pan and 
          Giancarlo Baldan and Oscar Beijbom},
  journal={arXiv preprint arXiv:1903.11027},
  year={2019}
}

@misc{https://doi.org/10.48550/arxiv.2106.09681,
  doi = {10.48550/ARXIV.2106.09681},
  
  url = {https://arxiv.org/abs/2106.09681},
  
  author = {El-Nouby, Alaaeldin and Touvron, Hugo and Caron, Mathilde and Bojanowski, Piotr and Douze, Matthijs and Joulin, Armand and Laptev, Ivan and Neverova, Natalia and Synnaeve, Gabriel and Verbeek, Jakob and Jegou, Hervé},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {XCiT: Cross-Covariance Image Transformers},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{el2021training,
  title={Training vision transformers for image retrieval},
  author={El-Nouby, Alaaeldin and Neverova, Natalia and Laptev, Ivan and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2102.05644},
  year={2021}
}

@misc{https://doi.org/10.48550/arxiv.2012.15840,
  doi = {10.48550/ARXIV.2012.15840},
  
  url = {https://arxiv.org/abs/2012.15840},
  
  author = {Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip H. S. and Zhang, Li},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{https://doi.org/10.48550/arxiv.2103.15691,
  doi = {10.48550/ARXIV.2103.15691},
  
  url = {https://arxiv.org/abs/2103.15691},
  
  author = {Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lučić, Mario and Schmid, Cordelia},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {ViViT: A Video Vision Transformer},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{bertasius2021space,
  title={Is space-time attention all you need for video understanding},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  journal={arXiv preprint arXiv:2102.05095},
  volume={2},
  number={3},
  pages={4},
  year={2021}
}

@misc{https://doi.org/10.48550/arxiv.2104.11227,
  doi = {10.48550/ARXIV.2104.11227},
  
  url = {https://arxiv.org/abs/2104.11227},
  
  author = {Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Multiscale Vision Transformers},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{zoph2020rethinking,
  title={Rethinking pre-training and self-training},
  author={Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung-Yi and Cui, Yin and Liu, Hanxiao and Cubuk, Ekin Dogus and Le, Quoc},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={3833--3845},
  year={2020}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}


@inproceedings{henaff2020dat
  title={Data-efficient image recognition with contrastive predictive coding},
  author={Henaff, Olivier},
  booktitle={International Conference on Machine Learning},
  pages={4182--4192},
  year={2020},
  organization={PMLR}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9650--9660},
  year={2021}
}

@article{caron2020unsupervised,
  title={Unsupervised learning of visual features by contrasting cluster assignments},
  author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9912--9924},
  year={2020}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21271--21284},
  year={2020}
}

@inproceedings{xie2021simmim,
  title={SimMIM: A Simple Framework for Masked Image Modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={International Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{lee2021vision,
  title={Vision Transformer for Small-Size Datasets},
  author={Lee, Seung Hoon and Lee, Seunghyun and Song, Byung Cheol},
  journal={arXiv preprint arXiv:2112.13492},
  year={2021}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  year={2017}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@article{xie2021moby,
  title={Self-Supervised Learning with Swin Transformers}, 
  author={Zhenda Xie and Yutong Lin and Zhuliang Yao and Zheng Zhang and Qi Dai and Yue Cao and Han Hu},
  journal={arXiv preprint arXiv:2105.04553},
  year={2021}
}

@article{liu2021swinV2,
  title={Swin Transformer V2: Scaling Up Capacity and Resolution},
  author={Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and others},
  journal={arXiv preprint arXiv:2111.09883},
  year={2021}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@article{touvron2022three,
  title={Three things everyone should know about Vision Transformers},
  author={Touvron, Hugo and Cord, Matthieu and El-Nouby, Alaaeldin and Verbeek, Jakob and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2203.09795},
  year={2022}
}

@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}

@article{dai2021coatnet,
  title={Coatnet: Marrying convolution and attention for all data sizes},
  author={Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3965--3977},
  year={2021}
}

@article{riquelme2021scaling,
  title={Scaling vision with sparse mixture of experts},
  author={Riquelme, Carlos and Puigcerver, Joan and Mustafa, Basil and Neumann, Maxim and Jenatton, Rodolphe and Susano Pinto, Andr{\'e} and Keysers, Daniel and Houlsby, Neil},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@misc{https://doi.org/10.48550/arxiv.2106.04560,
  doi = {10.48550/ARXIV.2106.04560},
  
  url = {https://arxiv.org/abs/2106.04560},
  
  author = {Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Scaling Vision Transformers},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{arkin2021survey,
  title={A Survey of Object Detection Based on CNN and Transformer},
  author={Arkin, Ershat and Yadikar, Nurbiya and Muhtar, Yusnur and Ubul, Kurban},
  booktitle={2021 IEEE 2nd International Conference on Pattern Recognition and Machine Learning (PRML)},
  pages={99--108},
  year={2021},
  organization={IEEE}
}

@article{goyal2021non,
  title={Non-deep networks},
  author={Goyal, Ankit and Bochkovskiy, Alexey and Deng, Jia and Koltun, Vladlen},
  journal={arXiv preprint arXiv:2110.07641},
  year={2021}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European conference on computer vision},
  pages={630--645},
  year={2016},
  organization={Springer}
}

@inproceedings{ding2021repvgg,
  title={Repvgg: Making vgg-style convnets great again},
  author={Ding, Xiaohan and Zhang, Xiangyu and Ma, Ningning and Han, Jungong and Ding, Guiguang and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13733--13742},
  year={2021}
}

@inproceedings{huang2016deep,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle={European conference on computer vision},
  pages={646--661},
  year={2016},
  organization={Springer}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{goyal2021non,
  title={Non-deep networks},
  author={Goyal, Ankit and Bochkovskiy, Alexey and Deng, Jia and Koltun, Vladlen},
  journal={arXiv preprint arXiv:2110.07641},
  year={2021}
}